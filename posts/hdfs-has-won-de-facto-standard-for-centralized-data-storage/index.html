<!doctype html><html lang=en dir=auto data-theme=dark><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>HDFS has won, now de facto standard for centralized data storage | Mark Chmarny</title><meta name=keywords content="oss,data,ml,hdfs,ml,hadoop,enterprise"><meta name=description content="The &ldquo;high-priests&rdquo; of Big Data have spoken. Hadoop Distributed File System (HDFS) is now the de facto standard platform for data storage. You may have heard this &ldquo;heresy&rdquo; uttered before. But, for me, it wasn’t until the recent Strata conference that I began to really understand how prevalent this opinion actually is."><meta name=author content="Mark Chmarny"><link rel=canonical href=https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/><link crossorigin=anonymous href=/assets/css/stylesheet.5bef4b698d33ee9d58f22269d129fe3c725b1b3356a4ed1ded10651b773f88c5.css integrity="sha256-W+9LaY0z7p1Y8iJp0Sn+PHJbGzNWpO0d7RBlG3c/iMU=" rel="preload stylesheet" as=style><link rel=icon href=https://blog.chmarny.com/favicons/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://blog.chmarny.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://blog.chmarny.com/favicon-32x32.png><link rel=apple-touch-icon href=https://blog.chmarny.com/apple-touch-icon.png><link rel=mask-icon href=https://blog.chmarny.com/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><script>localStorage.getItem("pref-theme")==="light"&&(document.querySelector("html").dataset.theme="light")</script><meta property="og:url" content="https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/"><meta property="og:site_name" content="Mark Chmarny"><meta property="og:title" content="HDFS has won, now de facto standard for centralized data storage"><meta property="og:description" content="The “high-priests” of Big Data have spoken. Hadoop Distributed File System (HDFS) is now the de facto standard platform for data storage. You may have heard this “heresy” uttered before. But, for me, it wasn’t until the recent Strata conference that I began to really understand how prevalent this opinion actually is."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2016-04-03T00:28:41+00:00"><meta property="article:modified_time" content="2016-04-03T00:28:41+00:00"><meta property="article:tag" content="Oss"><meta property="article:tag" content="Data"><meta property="article:tag" content="Hdfs"><meta property="article:tag" content="Ml"><meta property="article:tag" content="Hadoop"><meta property="article:tag" content="Enterprise"><meta property="og:image" content="https://blog.chmarny.com/images/site-feature-image.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.chmarny.com/images/site-feature-image.png"><meta name=twitter:title content="HDFS has won, now de facto standard for centralized data storage"><meta name=twitter:description content="The &ldquo;high-priests&rdquo; of Big Data have spoken. Hadoop Distributed File System (HDFS) is now the de facto standard platform for data storage. You may have heard this &ldquo;heresy&rdquo; uttered before. But, for me, it wasn’t until the recent Strata conference that I began to really understand how prevalent this opinion actually is."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://blog.chmarny.com/posts/"},{"@type":"ListItem","position":2,"name":"HDFS has won, now de facto standard for centralized data storage","item":"https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"HDFS has won, now de facto standard for centralized data storage","name":"HDFS has won, now de facto standard for centralized data storage","description":"The \u0026ldquo;high-priests\u0026rdquo; of Big Data have spoken. Hadoop Distributed File System (HDFS) is now the de facto standard platform for data storage. You may have heard this \u0026ldquo;heresy\u0026rdquo; uttered before. But, for me, it wasn’t until the recent Strata conference that I began to really understand how prevalent this opinion actually is.\n","keywords":["oss","data","ml","hdfs","ml","hadoop","enterprise"],"articleBody":"The “high-priests” of Big Data have spoken. Hadoop Distributed File System (HDFS) is now the de facto standard platform for data storage. You may have heard this “heresy” uttered before. But, for me, it wasn’t until the recent Strata conference that I began to really understand how prevalent this opinion actually is.\nPerhaps even more important, how big of an impact this approach to data storage is beginning to have on the architecture of our systems.\nSince the Strata conference, I’ve tried to reconcile this new role of HDFS with yet another major shift in system architecture: the increasing distinction between where data sleeps (as in where it is stored) and where data lives (as in where it is being used). Let me explain how one relates to the other, and why I actually now believe that HDFS is becoming the new, de facto standard for storing data.\nHDFS Overview HDFS is a fault-tolerant, distributed file system written entirely in Java. The core benefit of HDFS is in its ability to store large files across multiple machines; in distributed computing commonly referred to as “nodes”.\nBecause HDFS is designed for deployment on low-cost commodity hardware, it depends on software-based data partitioning to achieve its reliability. Traditional file systems would require the use of RAID to accomplish this same level of data durability, but, in HDFS’s case, it is done without dependency on the underlining hardware. HDFS divides large files into smaller individual blocks and distributes these blocks across multiple nodes.\nIt is important to note that HDFS is not a general-purpose file system. It does not provide fast individual record lookups, and, its file access speeds are pretty slow. However, despite these shortcomings, the appeal of HDFS as a free, reliable, centralized data repository capable of expanding with organizational needs is growing.\nBenefitting from the growing popularity of Hadoop, where HDFS is used as the underlining data storage, HDFS is increasingly viewed as the answer to the prevalent need for data collocation. Many feel that centralized data enables organizations to derive the maximum value from individual data sets. Because of these characteristics, organizations are increasingly willing to ignore the performance shortcoming of HDFS as a “database” and use it purely as a data repository.\nBefore you discredit this approach, please consider the ongoing changes that are taking place in on-line application architectures. Specifically the shift away from direct queries to the database and increasing reliance on law latency and high-speed data grids that are distributed, highly optimized, and most likely host the data in memory.\nShift in Data Access Patterns Increasingly, the place where data is stored (database) is not the place where the application data is managed. The illustration that perhaps most accurately reflects this shift is comparing data storage to the place where data sleeps and data application to the place where data lives.\nBuilding on this analogy, the place where data is stored does not need to be fast; it does however need to be reliable (fault-tolerant) and scalable (if I need more storage I just add more nodes).\nThis shift away from monolithic data stores is already visible in many of today’s Cloud-scale application architectures. Putting aside the IO limitations and the obsessive focus on atomicity, consistency, isolation, durability (ACID) of traditional databases, which leads to resource contention and subsequent locks. Simply maintaining speed of query execution as the data grows in these type of databases is physically impossible.\nBy contrast, new applications architected against in-memory data grids benefit from already “buffered” data, execute queries in parallel, and are able to asynchronously persist modifications to storage, so that these operations do not negatively impact their performance. This approach results in greater scalability of the overall application and delivers raw speed in order of magnitude compared to disk-based, traditional databases.\nIt is important to realize that these in-memory data grids are not dependent on the persistence mechanism and can leverage traditional databases as well as next-generation data storage platforms like HDFS.\nNew Data Storage Architecture As in-memory data grids become the backbone of next-generation on-line applications, their dependency on any specific data storage technology becomes less relevant. Overall, organizations want durable, scalable and low-cost data storage, and HDFS is increasingly becoming their consolidated data storage platform of choice.\nAs you can imagine, this is not an all-or-nothing situation. Whatever the specific workload is — write-intensive or demanding low-latency — HDFS can support these requirements with a variety of solutions. For example, an in-memory grid can be used for sub-second analytical processes of terabytes of data while persisting data to HDFS as a traditional data warehouse for back-office analytics.\nConsidering the relatively short life span of HDFS, its ecosystem often displays maturity. Solutions like Cloudera’s open source Impala can now run on the raw HDFS storage and expose it to on-line workloads through a familiar SQL interface without the overhead of MapReduce (as it is implemented by Hive).\nThe Kiji Project is another example of an open source framework building on top of HDFS to enable real-time data storage and service layer for applications. Impala and Kiji are just a few frameworks of what is likely to become a vibrant ecosystem.\nMany organizations have already started to leverage HDFS’s capabilities for various, non Hadoop-related applications. At Strata, I attended a session HDFS Integration presented by Todd Lipcon from Cloudera and Sanjay Radia from Hortonworks. It was a great overview of the vibrant technological integrations of HDFS with tools like Sqoop, Flume, FUSE or WebHDFS…just to name a few.\nHDFS has also a large set of native integration libraries in Java, C++, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk and many more. Additionally, HDFS has a powerful command-line and Web interface as well as Apache HBase project, which when necessary, can run on top of HDFS and enable fast record-level access for large data sets.\nOnce the data is centrally located, there is a well-documented concept of Data Gravity originally created by Dave McCrory, which among many other things has the effect of attracting new applications and potentially resulting in further increase of the data quality and overall value to an organization.\nI am not saying that all future data processing frameworks should be limited to HDFS. But, considering its prevalence in the Big Data market, low-cost, and scalability, and when combined with the vibrant ecosystem of libraries and project, it may be wise for organizations to start consider HDFS as their future-proof data storage platform.\n","wordCount":"1079","inLanguage":"en","image":"https://blog.chmarny.com/images/site-feature-image.png","datePublished":"2016-04-03T00:28:41.371Z","dateModified":"2016-04-03T00:28:41.371Z","author":{"@type":"Person","name":"Mark Chmarny"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/"},"publisher":{"@type":"Organization","name":"Mark Chmarny","logo":{"@type":"ImageObject","url":"https://blog.chmarny.com/favicons/favicon.ico"}}}</script></head><body id=top><header class=header><nav class=nav><div class=logo><a href=https://blog.chmarny.com/ accesskey=h title="Mark Chmarny (Alt + H)">Mark Chmarny</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://blog.chmarny.com/posts/ title=Posts><span>Posts</span></a></li><li><a href=https://blog.chmarny.com/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://blog.chmarny.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://blog.chmarny.com/archives/ title=Archives><span>Archives</span></a></li><li><a href=https://blog.chmarny.com/about/ title=About><span>About</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://blog.chmarny.com/>Home</a>&nbsp;»&nbsp;<a href=https://blog.chmarny.com/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">HDFS has won, now de facto standard for centralized data storage</h1><div class=post-meta><span title='2016-04-03 00:28:41.371 +0000 UTC'>2016-04-03</span>&nbsp;·&nbsp;<span>6 min</span>&nbsp;·&nbsp;<span>Mark Chmarny</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#hdfs-overview aria-label="HDFS Overview">HDFS Overview</a></li><li><a href=#shift-in-data-accesspatterns aria-label="Shift in Data Access Patterns">Shift in Data Access Patterns</a></li><li><a href=#new-data-storage-architecture aria-label="New Data Storage Architecture">New Data Storage Architecture</a></li></ul></div></details></div><div class=post-content><p>The &ldquo;high-priests&rdquo; of Big Data have spoken. Hadoop Distributed File System (<a href="http://hadoop.apache.org/docs/hdfs/current/hdfs_design.html&amp;t=ZjcxYWQyNjE5NTI5MjVjMGIyZDlhYTgwZDQ1ZmJkOWNiNjEwMjJiMixOSG5XdzVSRA%3D%3D">HDFS</a>) is now the de facto standard platform for data storage. You may have heard this &ldquo;heresy&rdquo; uttered before. But, for me, it wasn’t until the recent <a href=http://mark.chmarny.com/2012/10/stratahadoop-world-2012-etl-sql-other.html>Strata conference</a> that I began to really understand how prevalent this opinion actually is.</p><p><img loading=lazy src=/images/0__sG4Z__fWo4LsksKuM.jpg></p><p>Perhaps even more important, how big of an impact this approach to data storage is beginning to have on the architecture of our systems.</p><blockquote><p>Since the Strata conference, I’ve tried to reconcile this new role of HDFS with yet another major shift in system architecture: the increasing distinction between where data sleeps (as in where it is stored) and where data lives (as in where it is being used). Let me explain how one relates to the other, and why I actually now believe that HDFS is becoming the new, de facto standard for storing data.</p></blockquote><h2 id=hdfs-overview>HDFS Overview<a hidden class=anchor aria-hidden=true href=#hdfs-overview>#</a></h2><p>HDFS is a fault-tolerant, distributed file system written entirely in Java. The core benefit of HDFS is in its ability to store large files across multiple machines; in distributed computing commonly referred to as &ldquo;nodes&rdquo;.</p><p>Because HDFS is designed for deployment on low-cost commodity hardware, it depends on software-based data partitioning to achieve its reliability. Traditional file systems would require the use of <a href="http://en.wikipedia.org/wiki/RAID&amp;t=OTUwYjkwODg1NjY4ZjIwNzg3MDIzZDg4Njc1N2RjZmVlZGY2ZWQzMyxOSG5XdzVSRA%3D%3D">RAID</a> to accomplish this same level of data durability, but, in HDFS’s case, it is done without dependency on the underlining hardware. HDFS divides large files into smaller individual blocks and distributes these blocks across multiple nodes.</p><blockquote><p>It is important to note that HDFS is not a general-purpose file system. It does not provide fast individual record lookups, and, its file access speeds are pretty slow. However, despite these shortcomings, the appeal of HDFS as a free, reliable, centralized data repository capable of expanding with organizational needs is growing.</p></blockquote><p>Benefitting from the growing popularity of <a href="http://hadoop.apache.org/&amp;t=MmZhZDkxMWNhYzBhNTI0NWEyZDMxOTQ4NjQxNDBjOTIyMjAzZWExNSxOSG5XdzVSRA%3D%3D">Hadoop</a>, where HDFS is used as the underlining data storage, HDFS is increasingly viewed as the answer to the prevalent need for data collocation. Many feel that centralized data enables organizations to derive the maximum value from individual data sets. Because of these characteristics, organizations are increasingly willing to ignore the performance shortcoming of HDFS as a &ldquo;database&rdquo; and use it purely as a data repository.</p><p>Before you discredit this approach, please consider the ongoing changes that are taking place in on-line application architectures. Specifically the shift away from direct queries to the database and increasing reliance on law latency and high-speed data grids that are distributed, highly optimized, and most likely host the data in memory.</p><h2 id=shift-in-data-accesspatterns>Shift in Data Access Patterns<a hidden class=anchor aria-hidden=true href=#shift-in-data-accesspatterns>#</a></h2><p>Increasingly, the place where data is stored (database) is not the place where the application data is managed. The illustration that perhaps most accurately reflects this shift is comparing data storage to the place where data sleeps and data application to the place where data lives.</p><blockquote><p>Building on this analogy, the place where data is stored does not need to be fast; it does however need to be reliable (fault-tolerant) and scalable (if I need more storage I just add more nodes).</p></blockquote><p>This shift away from monolithic data stores is already visible in many of today’s Cloud-scale application architectures. Putting aside the IO limitations and the obsessive focus on atomicity, consistency, isolation, durability (ACID) of traditional databases, which leads to resource contention and subsequent locks. Simply maintaining speed of query execution as the data grows in these type of databases is physically impossible.</p><p><img loading=lazy src=/images/0__zYeIpzFojSlmkUxV.png></p><p>By contrast, new applications architected against in-memory data grids benefit from already &ldquo;buffered&rdquo; data, execute queries in parallel, and are able to asynchronously persist modifications to storage, so that these operations do not negatively impact their performance. This approach results in greater scalability of the overall application and delivers raw speed in order of magnitude compared to disk-based, traditional databases.</p><p>It is important to realize that these in-memory data grids are not dependent on the persistence mechanism and can leverage traditional databases as well as next-generation data storage platforms like HDFS.</p><h2 id=new-data-storage-architecture>New Data Storage Architecture<a hidden class=anchor aria-hidden=true href=#new-data-storage-architecture>#</a></h2><p>As in-memory data grids become the backbone of next-generation on-line applications, their dependency on any specific data storage technology becomes less relevant. Overall, organizations want durable, scalable and low-cost data storage, and HDFS is increasingly becoming their consolidated data storage platform of choice.</p><p>As you can imagine, this is not an all-or-nothing situation. Whatever the specific workload is — write-intensive or demanding low-latency — HDFS can support these requirements with a variety of solutions. For example, an in-memory grid can be used for sub-second analytical processes of terabytes of data while persisting data to HDFS as a traditional data warehouse for back-office analytics.</p><p>Considering the relatively short life span of HDFS, its ecosystem often displays maturity. Solutions like <a href="http://www.cloudera.com/content/cloudera/en/home.html&amp;t=ZjU1YWY4YTAzZmJlYTU5NzViZmM5NjFkNWRmMzM1NWEzMDIwZWZlYyxOSG5XdzVSRA%3D%3D">Cloudera’s</a> open source <a href="https://github.com/cloudera/impala&amp;t=NjBlM2EwNmZjNzhjNjU4NzQ1MjBjZDBmMjAwYWM2NWMzNTZjYjcyNixOSG5XdzVSRA%3D%3D">Impala</a> can now run on the raw HDFS storage and expose it to on-line workloads through a familiar SQL interface without the overhead of <a href="http://hadoop.apache.org/docs/r0.20.2/mapred_tutorial.html&amp;t=NzA2NmU1NWVlNWNlMmMxZDVjNTJmMDg0N2E5NTJiMWNjN2JkYWJkYSxOSG5XdzVSRA%3D%3D">MapReduce</a> (as it is implemented by <a href="http://hive.apache.org/&amp;t=MDc0NjUwYmRjYTcwMTNlMzJmYzdjZDVjMTczMTc3NjBjZDkzMDc3MixOSG5XdzVSRA%3D%3D">Hive</a>).</p><p>The <a href="https://github.com/kijiproject&amp;t=NmFjMGE2ODEwMGIzYzBkYWNmYTllMzIzOTk1MTM1N2RiZDUxMWQyNyxOSG5XdzVSRA%3D%3D">Kiji Project</a> is another example of an open source framework building on top of HDFS to enable real-time data storage and service layer for applications. Impala and Kiji are just a few frameworks of what is likely to become a vibrant ecosystem.</p><p>Many organizations have already started to leverage HDFS’s capabilities for various, non Hadoop-related applications. At Strata, I attended a session <a href="http://strataconf.com/stratany2012/public/schedule/detail/25679&amp;t=OWNkM2Y4OGQ2YmRlNGE5YzY5Y2Y3OTU0ZGEwZTIyNWZkNjk5YTNjOCxOSG5XdzVSRA%3D%3D">HDFS Integration</a> presented by <a href="http://www.linkedin.com/pub/todd-lipcon/5/169/3aa&amp;t=ODVmNWZjZDQzMzVjMmNiYzllZmNhYzliNjM0ZjM2MjA5OTIyZjA4MyxOSG5XdzVSRA%3D%3D">Todd Lipcon</a> from Cloudera and <a href="http://www.linkedin.com/pub/sanjay-radia/1/83/7a0&amp;t=ZWFlZDBjNzE5NTUxODJmNmZhZTFkODNlYzM0YThlMTUzOTQwMjEwNSxOSG5XdzVSRA%3D%3D">Sanjay Radia</a> from Hortonworks. It was a great overview of the vibrant technological integrations of HDFS with tools like <a href="http://sqoop.apache.org/&amp;t=OTEwMzQwY2U4MmFjM2ZhOWE4MzQ4YTcwOGMzMWIyZjA0OTBmNDBhZCxOSG5XdzVSRA%3D%3D">Sqoop</a>, <a href="http://flume.apache.org/&amp;t=MzU1MzI3YmUyNmU4MjVhNTY2MWYyZmQzOWY0ZTQyZGU5OGRjNzk3ZixOSG5XdzVSRA%3D%3D">Flume</a>, <a href="http://fuse.sourceforge.net/&amp;t=YTEzYzM3NGM4YjI1Y2I2Y2VjODE2ZmE1MjFiZjYzMzgyMzQ0N2UwOSxOSG5XdzVSRA%3D%3D">FUSE</a> or <a href="http://hadoop.apache.org/docs/r1.0.4/webhdfs.html&amp;t=MTVkZDMyZDc1OTQ2Nzg0MTdmMjdmZWZkOGQzNDJmNjJmYzNkNjRjYyxOSG5XdzVSRA%3D%3D">WebHDFS</a>…just to name a few.</p><p>HDFS has also a large set of native integration libraries in Java, C++, Python, PHP, Ruby, Erlang, Perl, Haskell, C#, Cocoa, Smalltalk and many more. Additionally, HDFS has a powerful command-line and Web interface as well as <a href="http://hbase.apache.org/&amp;t=NzA0NDhjN2FkOGQyNDYwNTgxNGZkNjM3OWNjZDZmMjM2M2E3ZmQ1OCxOSG5XdzVSRA%3D%3D">Apache HBase</a> project, which when necessary, can run on top of HDFS and enable fast record-level access for large data sets.</p><p><img loading=lazy src=/images/0__AnuIFK1RjHzUisXM.png></p><p>Once the data is centrally located, there is a well-documented concept of <a href="http://datagravity.org/&amp;t=NDhhZGMyYWQzMzdiNTZmMTg0OGU4YmRkZTE3MzhkNjFkMTM1ZWFmZixOSG5XdzVSRA%3D%3D">Data Gravity</a> originally created by <a href="http://www.linkedin.com/in/davemccrory&amp;t=MGE4ZTBkN2YxNjUyZmZjMmU0NGYxZTJlNDZlZjBlNjhjNGEyZjM2ZixOSG5XdzVSRA%3D%3D">Dave McCrory</a>, which among many other things has the effect of attracting new applications and potentially resulting in further increase of the data quality and overall value to an organization.</p><p>I am not saying that all future data processing frameworks should be limited to HDFS. But, considering its prevalence in the Big Data market, low-cost, and scalability, and when combined with the vibrant ecosystem of libraries and project, it may be wise for organizations to start consider HDFS as their future-proof data storage platform.</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://blog.chmarny.com/tags/oss/>Oss</a></li><li><a href=https://blog.chmarny.com/tags/data/>Data</a></li><li><a href=https://blog.chmarny.com/tags/hdfs/>Hdfs</a></li><li><a href=https://blog.chmarny.com/tags/ml/>Ml</a></li><li><a href=https://blog.chmarny.com/tags/hadoop/>Hadoop</a></li><li><a href=https://blog.chmarny.com/tags/enterprise/>Enterprise</a></li></ul><nav class=paginav><a class=prev href=https://blog.chmarny.com/posts/thinking-big-about-data-at-intel/><span class=title>« Prev</span><br><span>Thinking Big about Data at Intel</span>
</a><a class=next href=https://blog.chmarny.com/posts/dont-use-yesterday-database-to-develop-tomorrow-solutions/><span class=title>Next »</span><br><span>Don't use yesterday's database to develop tomorrow's solutions</span></a></nav></footer></article></main><footer class=footer><span>&copy; 2026 <a href=https://blog.chmarny.com/>Mark Chmarny</a></span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");if(menu){const e=localStorage.getItem("menu-scroll-position");e&&(menu.scrollLeft=parseInt(e,10)),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}}document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{const e=document.querySelector("html");e.dataset.theme==="dark"?(e.dataset.theme="light",localStorage.setItem("pref-theme","light")):(e.dataset.theme="dark",localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>