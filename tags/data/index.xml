<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data on Mark Chmarny</title><link>https://blog.chmarny.com/tags/data/</link><description>Recent content in Data on Mark Chmarny</description><generator>Hugo -- gohugo.io</generator><language>en</language><managingEditor>Mark Chmarny</managingEditor><lastBuildDate>Wed, 11 Jan 2023 07:09:34 -0800</lastBuildDate><atom:link href="https://blog.chmarny.com/tags/data/index.xml" rel="self" type="application/rss+xml"/><item><title>Software supply chain data fatigue and what I’ve learned from SBOM, vulnerability reports</title><link>https://blog.chmarny.com/posts/automating-software-supply-chain-security/</link><pubDate>Wed, 11 Jan 2023 07:09:34 -0800</pubDate><guid>https://blog.chmarny.com/posts/automating-software-supply-chain-security/</guid><description>&lt;p&gt;If you are doing any vulnerability detection in your software release pipeline today, you are already familiar with the volumes of data these scanners can generate. That dataset gets significantly larger when you add things like license scanning and &lt;a href="https://www.cisa.gov/sbom"&gt;Software Bill of Materials&lt;/a&gt; (SBOM) generation. That volume of data gets further compounded with each highly-automated pipeline you operate. This can quickly lead to what I refer to as a Software Supply Chain Security (S3C) data fatigue, as many vulnerabilities you’ll discover you simply can’t do anything about. There is an actionable signal in there actually, it’s just hard to find it in the midst of all the noise.&lt;/p&gt;</description></item><item><title>How I learned Dapr building tweet sentiment processing pipeline</title><link>https://blog.chmarny.com/posts/how-i-learned-dapr-building-tweet-sentiment-processing-pipeline/</link><pubDate>Sun, 10 May 2020 00:05:16 +0000</pubDate><guid>https://blog.chmarny.com/posts/how-i-learned-dapr-building-tweet-sentiment-processing-pipeline/</guid><description>&lt;p&gt;I recently joined the Office of CTO in Azure at Microsoft and wanted to ramp up on one of the open source projects the team has built there called Dapr. Dapr &lt;a href="https://dapr.io/"&gt;describes itself&lt;/a&gt; as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A portable, event-driven runtime that makes it easy for developers to build resilient, microservice stateless and stateful applications that run on the cloud and edge and embraces the diversity of languages and developer frameworks.&lt;/p&gt;</description></item><item><title>Renaissance of custom vertical solution</title><link>https://blog.chmarny.com/posts/renaissance-of-custom-vertical-solution/</link><pubDate>Wed, 19 Feb 2020 18:49:19 +0000</pubDate><guid>https://blog.chmarny.com/posts/renaissance-of-custom-vertical-solution/</guid><description>&lt;p&gt;We are entering a period where custom, highly-optimized, vertical solutions are becoming viable option again. This is a good news for ISVs with proven domain expertise and skilled development resources.&lt;/p&gt;
&lt;p&gt;Why do I think so? We now have:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Plethora of feature-rich developer frameworks, message queues, scalable data stores, and even lower-level components in the OSS community with great documentation and a large number of use-case validation&lt;/li&gt;
&lt;li&gt;Growing number of custom solution companies (more than just ISVs) with existing deep vertical/domain expertise who are also increasingly now investing in hiring and training strong development teams&lt;/li&gt;
&lt;li&gt;Virtually every Cloud provider offering either a raw Kubernetes service or managed container execution platform which (regardless how you feel about these technologies) creates ubiquitous surface area that can be addressed with a single solution&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Yes, there still are many ways in which these custom development efforts can fail. Still, as one who has started their professional career developing custom software, I’m glad to see how these kinds of efforts are becoming cost effective again and increasingly represent a viable option for differentiation and real business value delivery.&lt;/p&gt;</description></item><item><title>Data Exchange — How to Amplify Value of Machine Data</title><link>https://blog.chmarny.com/posts/data-exchange-how-to-amplify-value-of-machine-data/</link><pubDate>Tue, 17 May 2016 13:33:17 +0000</pubDate><guid>https://blog.chmarny.com/posts/data-exchange-how-to-amplify-value-of-machine-data/</guid><description>&lt;blockquote&gt;
&lt;p&gt;The presentation that goes along with this post is available &lt;a href="http://www.slideshare.net/MarkChmarny/machine-data-how-to-realize-and-amplify-its-value"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In &lt;a href="http://mark.chmarny.com/post/139001618764/service-not-volume-data-explosion-and-how-to"&gt;my last post&lt;/a&gt; I went over the value &lt;a href="http://mark.chmarny.com/post/139001618764/service-not-volume-data-explosion-and-how-to"&gt;cycle of machine generated data&lt;/a&gt;. In this post, I want to follow up with a few ideas on how to further amplify value of that data by expanding its context beyond the walls of owning organization, in a construct we came to know as Data Exchange, and list a few innovation opportunities in each one of these areas.&lt;/p&gt;</description></item><item><title>HDFS has won, now de facto standard for centralized data storage</title><link>https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/</link><pubDate>Sun, 03 Apr 2016 00:28:41 +0000</pubDate><guid>https://blog.chmarny.com/posts/hdfs-has-won-de-facto-standard-for-centralized-data-storage/</guid><description>&lt;p&gt;The &amp;ldquo;high-priests&amp;rdquo; of Big Data have spoken. Hadoop Distributed File System (&lt;a href="http://hadoop.apache.org/docs/hdfs/current/hdfs_design.html&amp;amp;t=ZjcxYWQyNjE5NTI5MjVjMGIyZDlhYTgwZDQ1ZmJkOWNiNjEwMjJiMixOSG5XdzVSRA%3D%3D"&gt;HDFS&lt;/a&gt;) is now the de facto standard platform for data storage. You may have heard this &amp;ldquo;heresy&amp;rdquo; uttered before. But, for me, it wasn’t until the recent &lt;a href="http://mark.chmarny.com/2012/10/stratahadoop-world-2012-etl-sql-other.html"&gt;Strata conference&lt;/a&gt; that I began to really understand how prevalent this opinion actually is.&lt;/p&gt;</description></item><item><title>Gluttony of great open ML tools too hard for enterprise to use</title><link>https://blog.chmarny.com/posts/gluttony-of-open-machine-intelligence-software-enterprise-finds-hard-to-use/</link><pubDate>Mon, 21 Sep 2015 11:40:45 +0000</pubDate><guid>https://blog.chmarny.com/posts/gluttony-of-open-machine-intelligence-software-enterprise-finds-hard-to-use/</guid><description>&lt;p&gt;Seems like every week we hear about yet another new open source Machine/Deep Learning library or Analytical Framework.&lt;/p&gt;
&lt;p&gt;Talking to people at &lt;a href="http://conferences.oreilly.com/strata/hadoop-big-data-eu"&gt;Strata this week&lt;/a&gt; only confirmed for me that in the midst of what can only be described as virtual gluttony of open-source software, there is massive number of organizations who find it increasingly harder to implement these technologies. Even the task of identifying the right solution can overwhelm many, and result in a tailspin of endless use-case/feature comparison.&lt;/p&gt;</description></item><item><title>Federated not Balkanized - The Future of Data and Its Short-term Cloud Challenges</title><link>https://blog.chmarny.com/posts/federated-not-balkanized-future-of-data-and-cloud-challenges/</link><pubDate>Tue, 21 Jul 2015 00:06:55 +0000</pubDate><guid>https://blog.chmarny.com/posts/federated-not-balkanized-future-of-data-and-cloud-challenges/</guid><description>&lt;p&gt;As a long-term Cloud storage user I recently wanted to re-evaluate my options. New content management providers became available and I wanted to make sure I wasn’t missing on the new shinny tech out there.&lt;/p&gt;
&lt;p&gt;As I was considering the pros and cons of each option, I realized the apparent shift in my personal attitude towards cloud data storage over last few years. My concerns used to be solely with security. Now, while the data security is still critical, I am much more interested in data access, ownership, integration and its control.&lt;/p&gt;</description></item><item><title>Data Opportunities, 3 Areas to Focus Innovation</title><link>https://blog.chmarny.com/posts/data-opportunities-3-areas-to-focus-innovation/</link><pubDate>Sat, 21 Feb 2015 00:33:24 +0000</pubDate><guid>https://blog.chmarny.com/posts/data-opportunities-3-areas-to-focus-innovation/</guid><description>&lt;p&gt;About a year and a half ago, I wrote about &lt;a href="https://blog.chmarny.com/posts/3-killer-big-data-app-opportunities.md"&gt;Big Data Opportunities&lt;/a&gt;, focusing primarily on Leveraging Unused Data, Driving New Value From Summary Data and Harnessing Heterogeneous Data Sensors (more recently known as &lt;a href="https://en.wikipedia.org/wiki/Internet_of_things"&gt;Internet of Things&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;&lt;img loading="lazy" src="https://blog.chmarny.com/images/0__FnPtGrT0LSmX6DBG.jpg"&gt;&lt;/p&gt;
&lt;p&gt;Since that post, data space has exploded with numerous solutions addressing many of these areas. These solutions while mostly based on batch operations and limited to serial MapReduce jobs against frequently off-line, inadequately secured, Hadoop cluster, they do allow access to previously inaccessible data.&lt;/p&gt;</description></item></channel></rss>